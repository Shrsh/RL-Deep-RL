{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "dqn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ooo0CADt_-O",
        "colab_type": "code",
        "outputId": "af7b9481-eaf2-46a6-82a1-adc19cb16709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from collections import deque, namedtuple\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3f0W4Vt_-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.envs.make(\"Breakout-v0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO1sHAFft_-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Atari Actions: 0 (noop), 1 (fire), 2 (left) and 3 (right) are valid actions\n",
        "VALID_ACTIONS = [0, 1, 2, 3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H1MtCXrt_-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StateProcessor():\n",
        "    \"\"\"\n",
        "    Processes a raw Atari images. Resizes it and converts it to grayscale.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Build the Tensorflow graph\n",
        "        with tf.variable_scope(\"state_processor\"):\n",
        "            self.input_state = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
        "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
        "            self.output = tf.image.crop_to_bounding_box(self.output, 34, 0, 160, 160)\n",
        "            self.output = tf.image.resize_images(\n",
        "                self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "            self.output = tf.squeeze(self.output)\n",
        "\n",
        "    def process(self, sess, state):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sess: A Tensorflow session object\n",
        "            state: A [210, 160, 3] Atari RGB State\n",
        "\n",
        "        Returns:\n",
        "            A processed [84, 84] state representing grayscale values.\n",
        "        \"\"\"\n",
        "        return sess.run(self.output, { self.input_state: state })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv_hUR9St_-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Estimator():\n",
        "    \"\"\"Q-Value Estimator neural network.\n",
        "\n",
        "    This network is used for both the Q-Network and the Target Network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scope=\"estimator\", summaries_dir=None):\n",
        "        self.scope = scope\n",
        "        # Writes Tensorboard summaries to disk\n",
        "        self.summary_writer = None\n",
        "        with tf.variable_scope(scope):\n",
        "            # Build the graph\n",
        "            self._build_model()\n",
        "            if summaries_dir:\n",
        "                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
        "                if not os.path.exists(summary_dir):\n",
        "                    os.makedirs(summary_dir)\n",
        "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the Tensorflow graph.\n",
        "        \"\"\"\n",
        "\n",
        "        # Placeholders for our input\n",
        "        # Our input are 4 grayscale frames of shape 84, 84 each\n",
        "        self.X_pl = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name=\"X\")\n",
        "        # The TD target value\n",
        "        self.y_pl = tf.placeholder(shape=[None], dtype=tf.float32, name=\"y\")\n",
        "        # Integer id of which action was selected\n",
        "        self.actions_pl = tf.placeholder(shape=[None], dtype=tf.int32, name=\"actions\")\n",
        "\n",
        "        X = tf.to_float(self.X_pl) / 255.0\n",
        "        batch_size = tf.shape(self.X_pl)[0]\n",
        "\n",
        "        # Three convolutional layers\n",
        "        conv1 = tf.contrib.layers.conv2d(\n",
        "            X, 32, 8, 4, activation_fn=tf.nn.relu)\n",
        "        conv2 = tf.contrib.layers.conv2d(\n",
        "            conv1, 64, 4, 2, activation_fn=tf.nn.relu)\n",
        "        conv3 = tf.contrib.layers.conv2d(\n",
        "            conv2, 64, 3, 1, activation_fn=tf.nn.relu)\n",
        "\n",
        "        # Fully connected layers\n",
        "        flattened = tf.contrib.layers.flatten(conv3)\n",
        "        fc1 = tf.contrib.layers.fully_connected(flattened, 512)\n",
        "        self.predictions = tf.contrib.layers.fully_connected(fc1, len(VALID_ACTIONS))\n",
        "\n",
        "        # Get the predictions for the chosen actions only\n",
        "        gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.actions_pl\n",
        "        self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)\n",
        "\n",
        "        # Calculate the loss\n",
        "        self.losses = tf.squared_difference(self.y_pl, self.action_predictions)\n",
        "        self.loss = tf.reduce_mean(self.losses)\n",
        "\n",
        "        # Optimizer Parameters from original paper\n",
        "        self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
        "        self.train_op = self.optimizer.minimize(self.loss, global_step=tf.contrib.framework.get_global_step())\n",
        "\n",
        "        # Summaries for Tensorboard\n",
        "        self.summaries = tf.summary.merge([\n",
        "            tf.summary.scalar(\"loss\", self.loss),\n",
        "            tf.summary.histogram(\"loss_hist\", self.losses),\n",
        "            tf.summary.histogram(\"q_values_hist\", self.predictions),\n",
        "            tf.summary.scalar(\"max_q_value\", tf.reduce_max(self.predictions))\n",
        "        ])\n",
        "\n",
        "\n",
        "    def predict(self, sess, s):\n",
        "        \"\"\"\n",
        "        Predicts action values.\n",
        "\n",
        "        Args:\n",
        "          sess: Tensorflow session\n",
        "          s: State input of shape [batch_size, 4, 84, 84, 1]\n",
        "\n",
        "        Returns:\n",
        "          Tensor of shape [batch_size, NUM_VALID_ACTIONS] containing the estimated \n",
        "          action values.\n",
        "        \"\"\"\n",
        "        return sess.run(self.predictions, { self.X_pl: s })\n",
        "\n",
        "    def update(self, sess, s, a, y):\n",
        "        \"\"\"\n",
        "        Updates the estimator towards the given targets.\n",
        "\n",
        "        Args:\n",
        "          sess: Tensorflow session object\n",
        "          s: State input of shape [batch_size, 4, 84, 84, 1]\n",
        "          a: Chosen actions of shape [batch_size]\n",
        "          y: Targets of shape [batch_size]\n",
        "\n",
        "        Returns:\n",
        "          The calculated loss on the batch.\n",
        "        \"\"\"\n",
        "        feed_dict = { self.X_pl: s, self.y_pl: y, self.actions_pl: a }\n",
        "        summaries, global_step, _, loss = sess.run(\n",
        "            [self.summaries, tf.contrib.framework.get_global_step(), self.train_op, self.loss],\n",
        "            feed_dict)\n",
        "        if self.summary_writer:\n",
        "            self.summary_writer.add_summary(summaries, global_step)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNAPpig0t_-q",
        "colab_type": "code",
        "outputId": "f982c855-9e96-476b-d336-343be5b6098e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "# For Testing....\n",
        "\n",
        "tf.reset_default_graph()\n",
        "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
        "\n",
        "e = Estimator(scope=\"test\")\n",
        "sp = StateProcessor()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Example observation batch\n",
        "    observation = env.reset()\n",
        "    \n",
        "    observation_p = sp.process(sess, observation)\n",
        "    observation = np.stack([observation_p] * 4, axis=2)\n",
        "    observations = np.array([observation] * 2)\n",
        "    \n",
        "    # Test Prediction\n",
        "    print(e.predict(sess, observations))\n",
        "\n",
        "    # Test training step\n",
        "    y = np.array([10.0, 10.0])\n",
        "    a = np.array([1, 3])\n",
        "    print(e.update(sess, observations, a, y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-fccad5a91a11>:33: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-fccad5a91a11>:59: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "[[0.06801608 0.05007149 0.0129574  0.02609448]\n",
            " [0.06801608 0.05007149 0.0129574  0.02609448]]\n",
            "99.23993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GmteZSnt_-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def copy_model_parameters(sess, estimator1, estimator2):\n",
        "    \"\"\"\n",
        "    Copies the model parameters of one estimator to another.\n",
        "\n",
        "    Args:\n",
        "      sess: Tensorflow session instance\n",
        "      estimator1: Estimator to copy the paramters from\n",
        "      estimator2: Estimator to copy the parameters to\n",
        "    \"\"\"\n",
        "    e1_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator1.scope)]\n",
        "    e1_params = sorted(e1_params, key=lambda v: v.name)\n",
        "    e2_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator2.scope)]\n",
        "    e2_params = sorted(e2_params, key=lambda v: v.name)\n",
        "\n",
        "    update_ops = []\n",
        "    for e1_v, e2_v in zip(e1_params, e2_params):\n",
        "        op = e2_v.assign(e1_v)\n",
        "        update_ops.append(op)\n",
        "\n",
        "    sess.run(update_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LApMIkC3t_-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_epsilon_greedy_policy(estimator, nA):\n",
        "    \"\"\"\n",
        "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
        "\n",
        "    Args:\n",
        "        estimator: An estimator that returns q values for a given state\n",
        "        nA: Number of actions in the environment.\n",
        "\n",
        "    Returns:\n",
        "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
        "        the probabilities for each action in the form of a numpy array of length nA.\n",
        "\n",
        "    \"\"\"\n",
        "    def policy_fn(sess, observation, epsilon):\n",
        "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
        "        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n",
        "        best_action = np.argmax(q_values)\n",
        "        A[best_action] += (1.0 - epsilon)\n",
        "        return A\n",
        "    return policy_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADXCFJwht_-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_q_learning(sess,\n",
        "                    env,\n",
        "                    q_estimator,\n",
        "                    target_estimator,\n",
        "                    state_processor,\n",
        "                    num_episodes,\n",
        "                    experiment_dir,\n",
        "                    replay_memory_size=500000,\n",
        "                    replay_memory_init_size=50000,\n",
        "                    update_target_estimator_every=10000,\n",
        "                    discount_factor=0.99,\n",
        "                    epsilon_start=0.8,\n",
        "                    epsilon_end=0.1,\n",
        "                    epsilon_decay_steps=500000,\n",
        "                    batch_size=1,\n",
        "                    record_video_every=90):\n",
        "    \"\"\"\n",
        "    Q-Learning algorithm for off-policy TD control using Function Approximation.\n",
        "    Finds the optimal greedy policy while following an epsilon-greedy policy.\n",
        "\n",
        "    Args:\n",
        "        sess: Tensorflow Session object\n",
        "        env: OpenAI environment\n",
        "        q_estimator: Estimator object used for the q values\n",
        "        target_estimator: Estimator object used for the targets\n",
        "        state_processor: A StateProcessor object\n",
        "        num_episodes: Number of episodes to run for\n",
        "        experiment_dir: Directory to save Tensorflow summaries in\n",
        "        replay_memory_size: Size of the replay memory\n",
        "        replay_memory_init_size: Number of random experiences to sampel when initializing \n",
        "          the reply memory.\n",
        "        update_target_estimator_every: Copy parameters from the Q estimator to the \n",
        "          target estimator every N steps\n",
        "        discount_factor: Gamma discount factor\n",
        "        epsilon_start: Chance to sample a random action when taking an action.\n",
        "          Epsilon is decayed over time and this is the start value\n",
        "        epsilon_end: The final minimum value of epsilon after decaying is done\n",
        "        epsilon_decay_steps: Number of steps to decay epsilon over\n",
        "        batch_size: Size of batches to sample from the replay memory\n",
        "        record_video_every: Record a video every N episodes\n",
        "\n",
        "    Returns:\n",
        "        An EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n",
        "    \"\"\"\n",
        "\n",
        "    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "    # The replay memory\n",
        "    replay_memory = []\n",
        "\n",
        "    # Keeps track of useful statistics\n",
        "    # like episode length, episode reward\n",
        "    stats = {\"episode_lengths\":np.zeros(num_episodes), \"episode_rewards\":np.zeros(num_episodes)}\n",
        "    # average episode reward for past n episodes\n",
        "\n",
        "    # Create directories for checkpoints and summaries\n",
        "    checkpoint_dir = os.path.join(experiment_dir, \"checkpoints\")\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
        "    monitor_path = os.path.join(experiment_dir, \"monitor\")\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    if not os.path.exists(monitor_path):\n",
        "        os.makedirs(monitor_path)\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    # Load a previous checkpoint if we find one\n",
        "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    if latest_checkpoint:\n",
        "        print(\"Loading model checkpoint {}...\\n\".format(latest_checkpoint))\n",
        "        saver.restore(sess, latest_checkpoint)\n",
        "    \n",
        "    # Get the current time step\n",
        "    total_t = sess.run(tf.contrib.framework.get_global_step())\n",
        "\n",
        "    # The epsilon decay schedule\n",
        "    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n",
        "\n",
        "    # The policy we're following\n",
        "    policy = make_epsilon_greedy_policy(\n",
        "        q_estimator,\n",
        "        len(VALID_ACTIONS))\n",
        "\n",
        "    # Populate the replay memory with initial experience\n",
        "    print(\"Populating replay memory...\")\n",
        "    state = env.reset()\n",
        "    state = state_processor.process(sess, state)\n",
        "    state = np.stack([state] * 4, axis=2)\n",
        "    for i in range(replay_memory_init_size):\n",
        "        action_probs = policy(sess, state, epsilons[min(total_t, epsilon_decay_steps-1)])\n",
        "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "        next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
        "        next_state = state_processor.process(sess, next_state)\n",
        "        next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
        "        # TODO: Populate replay memory!\n",
        "        if done:\n",
        "            state = env.reset()\n",
        "            state = state_processor.process(sess, state)\n",
        "            state = np.stack([state] * 4, axis=2)\n",
        "        else:\n",
        "            state = next_state\n",
        "\n",
        "    # Record videos\n",
        "    env= Monitor(env,\n",
        "                 directory=monitor_path,\n",
        "                 resume=True,\n",
        "                 video_callable=lambda count: count % record_video_every == 0)\n",
        "\n",
        "    for i_episode in range(num_episodes):\n",
        "\n",
        "        # Save the current checkpoint\n",
        "        saver.save(tf.get_default_session(), checkpoint_path)\n",
        "\n",
        "        # Reset the environment\n",
        "        state = env.reset()\n",
        "        state = state_processor.process(sess, state)\n",
        "        state = np.stack([state] * 4, axis=2)\n",
        "        loss = None\n",
        "\n",
        "        path_2 = \"drive/My Drive/atari_experiments/experiments/\"\n",
        "        complete_name_2 = os.path.join(path_2,'q_values'+'.txt')\n",
        "\n",
        "\n",
        "\n",
        "        # One step in the environment\n",
        "        for t in itertools.count():\n",
        "\n",
        "            # Epsilon for this time step\n",
        "            epsilon = epsilons[min(total_t, epsilon_decay_steps-1)]\n",
        "            # Add epsilon to Tensorboard\n",
        "            episode_summary = tf.Summary()\n",
        "            episode_summary.value.add(simple_value=epsilon, tag=\"epsilon\")\n",
        "            q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
        "\n",
        "            # TODO: Maybe update the target estimator\n",
        "            if total_t % update_target_estimator_every == 0:\n",
        "                copy_model_parameters(sess, q_estimator, target_estimator)\n",
        "                # print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n",
        "                    # t, total_t, i_episode + 1, num_episodes, loss), end=\"\")\n",
        "                # print('\\n' + str(epsilon))\n",
        "                \n",
        "\n",
        "            # Print out which step we're on, useful for debugging.\n",
        "            # print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n",
        "            #         t, total_t, i_episode + 1, num_episodes, loss), end=\"\")\n",
        "            # sys.stdout.flush()\n",
        "\n",
        "            # Take a step in the environment\n",
        "            # TODO: Implement!\n",
        "            action_probs = policy(sess, state, epsilon)\n",
        "            action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "            next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
        "            if total_t % update_target_estimator_every == 0:\n",
        "              print('done')\n",
        "              matplotlib.pyplot.imsave('drive/My Drive/atari_experiments/experiments/screenshot' + str(total_t) + '.png', next_state)\n",
        "            next_state = state_processor.process(sess, next_state)\n",
        "            next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "\n",
        "\n",
        "            # If our replay memory is full, pop the first element\n",
        "            if len(replay_memory) == replay_memory_size:\n",
        "                replay_memory.pop(0)\n",
        "\n",
        "            # TODO: Save transition to replay memory\n",
        "            replay_memory.append(Transition(state, action, reward, next_state, done))   \n",
        "\n",
        "            # Update statistics\n",
        "            stats['episode_rewards'][i_episode] += reward\n",
        "            stats['episode_lengths'][i_episode] = t\n",
        "            # print(stats['episode_rewards'][i_episode])\n",
        "            # TODO: Sample a minibatch from the replay memory\n",
        "            samples = random.sample(replay_memory, batch_size)\n",
        "            states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
        "\n",
        "            # TODO: Calculate q values and targets\n",
        "            q_values_next = target_estimator.predict(sess, next_states_batch)\n",
        "            targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * discount_factor * np.amax(q_values_next, axis=1)\n",
        "\n",
        "            if total_t % update_target_estimator_every == 0:\n",
        "              file_q = open(complete_name_2,\"a\")\n",
        "              file_q.write(str(q_values_next) + '\\n')\n",
        "              file_q.close()\n",
        "\n",
        "            # TODO Perform gradient descent update\n",
        "            states_batch = np.array(states_batch)\n",
        "            loss = q_estimator.update(sess, states_batch, action_batch, targets_batch)\n",
        "\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            state = next_state\n",
        "            total_t += 1\n",
        "\n",
        "        # Add summaries to tensorboard\n",
        "        episode_summary = tf.Summary()\n",
        "        episode_summary.value.add(simple_value=stats['episode_rewards'][i_episode], node_name=\"episode_reward\", tag=\"episode_reward\")\n",
        "        episode_summary.value.add(simple_value=stats['episode_lengths'][i_episode], node_name=\"episode_length\", tag=\"episode_length\")\n",
        "        q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
        "        q_estimator.summary_writer.flush()\n",
        "\n",
        "        yield total_t, stats[\"episode_lengths\"][i_episode], stats[\"episode_rewards\"][i_episode] \n",
        "    # env.monitor.close()\n",
        "    return stats\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHgAATKpt__A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# Where we save our checkpoints and graphs\n",
        "experiment_dir = os.path.abspath(\"drive/My Drive/atari_experiments/experiments/{}\".format(env.spec.id))\n",
        "\n",
        "# Create a glboal step variable\n",
        "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "    \n",
        "# Create estimators\n",
        "q_estimator = Estimator(scope=\"q\", summaries_dir=experiment_dir)\n",
        "target_estimator = Estimator(scope=\"target_q\")\n",
        "\n",
        "#save_reward_file\n",
        "path = \"drive/My Drive/atari_experiments/experiments/\"\n",
        "complete_name = os.path.join(path,'rewards_file'+'.txt')\n",
        "\n",
        "\n",
        "# State processor\n",
        "state_processor = StateProcessor()\n",
        "\n",
        "episode_average_reward = []\n",
        "reward_sum =0 \n",
        "count = 0 \n",
        "# Run it!\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    for t in deep_q_learning(sess,\n",
        "                             env,\n",
        "                             q_estimator=q_estimator,\n",
        "                             target_estimator=target_estimator,\n",
        "                             state_processor=state_processor,\n",
        "                             experiment_dir=experiment_dir,\n",
        "                             num_episodes=1000,\n",
        "                             replay_memory_size=500000,\n",
        "                             replay_memory_init_size=50000,\n",
        "                             update_target_estimator_every=10000,\n",
        "                             epsilon_start=0.1,\n",
        "                             epsilon_end=0.1,\n",
        "                             epsilon_decay_steps=2800000,\n",
        "                             discount_factor=0.99,\n",
        "                             batch_size=1):\n",
        "        #counting average reward per 30 episodes\n",
        "        count+=1\n",
        "        reward_sum+=t[2]\n",
        "        if count%30 == 0 :\n",
        "          file2= open(complete_name,\"a\")\n",
        "          episode_average_reward.append(reward_sum/30)\n",
        "          file2.write(str(reward_sum/30) + \"\\n\")\n",
        "          reward_sum = 0 \n",
        "          count=0\n",
        "          file2.close()\n",
        "    # print(episode_average_reward)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROREcvMSS9qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_CgIL62TMTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mkIPbnGfVnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9_AOQySfkQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gbpD6xfy5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS9BeM7jgBjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVZWJR7ggQNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC-FeLoVge2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AA0Aipugtf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKigvMPkg8Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyo8UOPqhKzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiLT4y55hZca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsHMvRIxhoF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUmVlwujh2vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUFi_lIbiFZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnhhOa-7iUCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKtJVDkuiir1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBddHkWZixVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDPLKuo5i__G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpP0ksyKjOoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M7Agjg0jdSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEOOuwEljr7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBiUsVtqj6lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4BAcowYkJOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhIWraHbkX4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_R9zQy2kmhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFsMZ7fTk1LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxmIk0VWlD0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ODmxdo5lSeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rwDQ763lhHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaBR8vCSlvxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZdPvXuil-aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzCPRG4LmNEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRiw8P6mbtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSm7SmqSmqXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BQD_IlSm5Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRVUX230nHqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDjgKcl1nWTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ-_TYe8nk9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKwK8GBrnzmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoKzPm1ioCQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I06N8EuIoQ5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OgUpkEofjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSU_3vlouMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqSuAomJo82T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g51-NnfgpLfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twRs7j3TpaJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H_w5z1apoyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXyrdaMnp3cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joGBbwnwqGFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-8cifWqUvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGpl8kUlqjY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDE5zikqyCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQiIBk2JrArx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWDm8tpjrPVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kul6WW_Krd-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mTfYKpVrsoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA5Z6jEUr7Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6MO2vUBsJ7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m58P-nH-sYkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOEHAavbsnOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr_KzZOqs130",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8kjWKF9tEhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPelrFfstTKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggm-AsRkth0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZUU_sfdtwdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndurs_kVt_HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTsbXPKEuNwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B0BhNNvucaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "047HAWzqurD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJgjhydfu5tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGYQTu9vIW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XFwy2pqvXAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXj-ZFQqvlp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJibmxqtv0Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfwabVCJwC8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdC0QhCJwRmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRwsnC3XwgP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W30Wxldowu5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ch35Gjrw9i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZsEAjBDxMMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-roaGhWkTa9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZYUwlQWTpnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF3U-7hhT4QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45a0ePJwUG5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbEgqlowUVd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3m_gtZBUkHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlU7Mwk3Uywk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aBOM0vmVBaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bbvVhbGVQD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftVvcgP0Veth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCGUrR0QVtXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgyRLvMTV8AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGQc1RLCWKqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCmdSb5TWZTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1-g0VCMWn9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siav4d2wW2mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4He12yBsXFQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KTGyYh8XT5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sixWBQEXii3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucFF1p04XxMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xpa8DJ3N7WH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQtsUc4ROJ9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0amR4IVOYnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSXM4AhbOnRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0p1WZq9O2Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIX03s3fPEpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM1U0DKwPTSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F6PWlwTPh5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVL0xbTNPwg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiivdNAWP_Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUTAOYPzQNzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17C_RyBIQcdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VgJdFVdQtQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTuC6CTFQ5vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2gU3oegRIYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ncquXmRXCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iiMR5KuRlrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3980srX8R0VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLQQqg5_SC-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RIOWj-7SRoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhzsFa7qSgRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHDSFJDCSu7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbuq9BKYt__G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(episodes)\n",
        "print(episode_average_reward)\n",
        "matplotlib.pyplot.plot(np.array(episodes), np.array(episode_average_reward))\n",
        "matplotlib.pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35uGerFY62Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUs-ErkXL3fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyex8bIxMGIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTkJkVmMUye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ekkUdMQMjbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT-LqgCwMyE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPmLJMsXNAur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTaI-3ToNPYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oDPZWMhNeBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEI0pefSNsrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ3RAx6zb4V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}